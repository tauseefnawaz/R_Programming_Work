{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKgOjQaUdEoN"
   },
   "source": [
    "#ESCP MIDITAL - BIG DATA AND ANALYTICS\n",
    "##FINAL ASSESSMENT\n",
    "\n",
    "##STUDENT NAME:\n",
    "##STUDENT NUMBER:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_bV5FKA8pFm"
   },
   "source": [
    "<img src=\"https://github.com/l0g1c4p3/escp/blob/master/flowmeter.png?raw=true\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmacBhSDOa9V"
   },
   "source": [
    "## ESCP MIDITAL 2020-21\n",
    "#Fault diagnosis of four liquid ultrasonic flowmeters\n",
    "\n",
    "This dataset contains 87 instances of diagnostic parameters for an 8-path liquid ultrasonic flow meter.\n",
    "\n",
    "It has 37 attributes and a target representing 2 classes or health states:\n",
    "All attributes are continuous, with the exception of the TARGET attribute.\n",
    "\n",
    "Note that these are separate non-sequential samples and they do not represent a time series.\n",
    "\n",
    "\n",
    "* FR -- Flatness ratio\n",
    "* SY -- Symmetry\n",
    "* CF -- Crossflow\n",
    "* FVP(1-8) -- Flow velocity in each of the eight paths\n",
    "* SSP(1-8) -- Speed of sound in each of the eight paths\n",
    "* SSAVG -- Average speed of sound in all eight paths\n",
    "* G(A/B)P(1-8) -- Gain at both ends of each of the eight paths\n",
    "* TARGET -- Class attribute or health state of meter:\n",
    " * 1 - Healthy\n",
    " * 2 - Installation effects\n",
    "\n",
    "\n",
    "The main objective of the assignment is to explore the dataset and then create a model able to predict when a flowmeter readings indicate a fault in the system.\n",
    "\n",
    "\n",
    "Relevant Papers:\n",
    "K. S. Gyamfi, J. Brusey, A. Hunt, E. Gaura , Linear dimensionality reduction for classification via a sequential Bayes error minimisation with an application to flow meter diagnostics, Expert Systems with Applications (IF: 3.928), September 2017\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXuyp6MjNqe4"
   },
   "outputs": [],
   "source": [
    "#Importing the necessary packages and libaries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLAdN1WwqLbc"
   },
   "source": [
    "Read the data into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59lEXZdTu2aM",
    "outputId": "9a9a959e-3c9a-422e-dbee-be024f699656"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 37)"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"https://github.com/l0g1c4p3/escp/blob/master/Meter_A.xlsx?raw=true\")\n",
    "\n",
    "#check its shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P01sGS62qeiL"
   },
   "source": [
    "Separate the data and the targets into separate ndarrays x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZ5raE61m8s9",
    "outputId": "aff0abb4-4688-4e3b-fdeb-5bc4ab49c6bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 36)\n",
      "(87, 1)\n"
     ]
    }
   ],
   "source": [
    "x = (df[df.columns[:-1]]).values\n",
    "y = df.loc[:,['TARGET']].values\n",
    "\n",
    "#check their shape\n",
    "print (x.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFh_VTUbu5lp"
   },
   "source": [
    "#1\n",
    "Explore the data: \n",
    "Print a table of all the descriptive statistics (count, mean, std deviation, min, max etc) are there any of the values negative?\n",
    "If the data is not normalised, please do so using the MinMaxScaler to constrain all variables to the interval 0 to 1\n",
    "\n",
    "---\n",
    "[Attention: Do not normalise the target variable!]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWu8BSB45C1x"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mgj3Du6wyanV"
   },
   "source": [
    "#2\n",
    "\n",
    "Explore the data: plot the distribution of SY and CF (better if you manage to use the same plot), to see what they look like\n",
    "\n",
    "---\n",
    "Do not attempt to use a pairplot on the entire dataframe because there are too many variables and it is likely to freeze or take a very long time and then result illegible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ogAXs7Tkn_pz"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4rRtPMCrjfM"
   },
   "source": [
    "#3\n",
    "Explore the data:\n",
    "print a heatmap of the correlations between all the variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HT3MoGjAmhg_"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kefJ99Ct4iem"
   },
   "source": [
    "#4\n",
    "Use a boxplot to plot only the subset of variables SSP1-SSP8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlJOk1bz47Rb"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdKaY2h-xPC9"
   },
   "source": [
    "#5\n",
    "Plot CF vs GBP4 and use colour to distinguish samples of the two target classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nuv_vdB9i8T1"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnl3JS1CtL8I"
   },
   "source": [
    "#6\n",
    "Now use a scatter plot to show GAP5 vs GBP4 and add a second order polynomial regression line\n",
    "\n",
    "Run the regression using scikit learn and find the coefficients of the polynomial regression line (no need to split train/test yet, just use the entire data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYr5yXGWTjO5"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20t_5yIBfg8Q"
   },
   "source": [
    "#7\n",
    "Let us explore the potential of the dataset to create a model for fault prediction. \n",
    "\n",
    "First we need to check if the two classes (1:healthy and 2:faulty) are fairly balanced (let's say that the number of samples in a class should not be more than twice the number in the other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEsp0QQUsDqB"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RcXzW7sF1t-J"
   },
   "source": [
    "#8\n",
    "Use Principal Component Analysis to transform the data so that each subsequent feature carries the maximum possible information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMdjCmCD7Hfh"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMfBziO82wpq"
   },
   "source": [
    "#9\n",
    "If we want to use this information to do dimensionality reduction, we need to plot a graph and a table of how much cumulative variance is explained the features. If we use a cut-off of 99% explained variance, how many features we should keep?\n",
    "\n",
    "Create a new ndarray, keeping only these components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dG1NNukQzNob"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTVO2f-I3JfG"
   },
   "source": [
    "#10\n",
    "Now let's start creating our model. First split the dataset in 75% and 25% of the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mg1fZqzD3E0N"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCOOnkkZ3Y7y"
   },
   "source": [
    "#11\n",
    "Train both a decision tree classifier and a SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JauIF_Oq3Ni4"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDZAVkaB3pPS"
   },
   "source": [
    "#12\n",
    "Print the accuracies and the confusion matrices of both classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxCy9oTj6vy4"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOOiEps631SH"
   },
   "source": [
    "#13\n",
    "\n",
    "Try to tweak the hyperparamenters of the classifiers to obtain the best possible performance out of them.\n",
    "\n",
    "How can you explain their level of performance? What would be some ideas to improve it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3ji2__w6aJb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5Gw2VUk4MaA"
   },
   "source": [
    "#14\n",
    "If you have additional explorations or models that you wish to run on the data, add them below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56VN70KY5ibA"
   },
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ESCP_FA_2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
